{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30524e7f-717f-42fb-9aaf-b62686c99f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from scipy.sparse import csc_matrix\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def preprocess_data(dfTrain, dfTest):\n",
    "    # Assuming dfTrain and dfTest are already defined\n",
    "    # Drop unnecessary columns and preprocess longitude values for dfTrain\n",
    "    dfTrain = dfTrain.drop(columns=['trans_date_trans_time', 'dob', 'trans_num', 'Unnamed: 0'])\n",
    "    dfTrain['long'] = (dfTrain['long'] + 360) % 360\n",
    "    dfTrain['merch_long'] = (dfTrain['merch_long'] + 360) % 360\n",
    "\n",
    "    # Drop unnecessary columns and preprocess longitude values for dfTest\n",
    "    dfTest = dfTest.drop(columns=['trans_date_trans_time', 'dob', 'trans_num', 'Unnamed: 0'])\n",
    "    dfTest['long'] = (dfTest['long'] + 360) % 360\n",
    "    dfTest['merch_long'] = (dfTest['merch_long'] + 360) % 360\n",
    "\n",
    "    # Separate categorical and numerical columns for dfTrain\n",
    "    categorical_cols = ['merchant', 'category', 'first', 'last', 'gender', 'street', 'city', 'state', 'job']\n",
    "    numerical_cols = [col for col in dfTrain.columns if col not in categorical_cols + ['is_fraud']]\n",
    "\n",
    "    # Separate features and target variable for dfTrain\n",
    "    X_train = dfTrain.drop(columns=['is_fraud'])\n",
    "    y_train = dfTrain['is_fraud']\n",
    "\n",
    "    # Separate features and target variable for dfTest\n",
    "    X_test = dfTest.drop(columns=['is_fraud'])\n",
    "    y_test = dfTest['is_fraud']\n",
    "\n",
    "    # Get the indices of the numerical columns\n",
    "    numerical_indices = [dfTrain.columns.get_loc(col) for col in numerical_cols]\n",
    "\n",
    "    # Use SelectKBest with chi-squared test to select top features\n",
    "    selector = SelectKBest(score_func=chi2, k=5)  # Select top 5 features based on chi-squared test\n",
    "    X_train_selected = selector.fit_transform(X_train.iloc[:, numerical_indices], y_train)\n",
    "    X_test_selected = selector.transform(X_test.iloc[:, numerical_indices])\n",
    "\n",
    "    # Get the indices of the selected features\n",
    "    selected_indices = selector.get_support(indices=True)\n",
    "\n",
    "    # Get the names of the selected features\n",
    "    selected_feature_names = [numerical_cols[i] for i in selected_indices]\n",
    "\n",
    "\n",
    "    # Assuming you have already processed the dataset and named it df_processed\n",
    "    # Define the categorical and numerical columns based on the processed dataset\n",
    "    categorical_cols = ['merchant', 'category', 'first', 'last', 'gender', 'street', 'city', 'state', 'job']\n",
    "    numerical_cols = ['cc_num', 'amt', 'city_pop', 'unix_time']\n",
    "    is_fraud=['is_fraud']\n",
    "\n",
    "\n",
    "    # Create a new dataset with only the specified columns\n",
    "    new_df_Train = dfTrain[categorical_cols + numerical_cols+is_fraud]\n",
    "    new_df_Test=dfTest[categorical_cols + numerical_cols+is_fraud]\n",
    "\n",
    "\n",
    "    # Ensure 'is_fraud' is included for target variable in both datasets\n",
    "    new_df_Train = new_df_Train[categorical_cols + numerical_cols + ['is_fraud']]\n",
    "    new_df_Test = new_df_Test[categorical_cols + numerical_cols + ['is_fraud']]\n",
    "\n",
    "    # Encode categorical columns using LabelEncoder for new_df_Train\n",
    "    train_encoded = new_df_Train.copy()\n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        train_encoded[col] = le.fit_transform(new_df_Train[col])\n",
    "\n",
    "    # Encode categorical columns using LabelEncoder for new_df_Test\n",
    "    test_encoded = new_df_Test.copy()\n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        test_encoded[col] = le.fit_transform(new_df_Test[col])\n",
    "\n",
    "    # Separate features and target variable for new_df_Train\n",
    "    X_train = train_encoded[categorical_cols + numerical_cols]\n",
    "    y_train = train_encoded['is_fraud']\n",
    "\n",
    "    # Separate features and target variable for new_df_Test\n",
    "    X_test = test_encoded[categorical_cols + numerical_cols]\n",
    "    y_test = test_encoded['is_fraud']\n",
    "\n",
    "    # Use SelectKBest with chi-squared test to select top categorical features\n",
    "    categorical_selector = SelectKBest(score_func=chi2, k='all')  # Use 'all' to get scores for all features\n",
    "    X_cat_selected = categorical_selector.fit_transform(X_train[categorical_cols], y_train)\n",
    "\n",
    "    # Get the scores for each categorical feature\n",
    "    categorical_scores = categorical_selector.scores_\n",
    "\n",
    "    # Create a DataFrame to display the scores\n",
    "    cat_feature_scores = pd.DataFrame({'Feature': categorical_cols, 'Score': categorical_scores})\n",
    "    cat_feature_scores = cat_feature_scores.sort_values(by='Score', ascending=False)\n",
    "\n",
    "\n",
    "    new_categorical_cols = ['category']\n",
    "    new_df_Test = new_df_Test[new_categorical_cols + numerical_cols+is_fraud]\n",
    "    new_df_Train=new_df_Train[new_categorical_cols + numerical_cols+is_fraud]\n",
    "\n",
    "\n",
    "\n",
    "    # Assuming new_df_Train and new_df_Test are already defined\n",
    "    # Define the important categorical features\n",
    "    new_categorical_cols = ['category']\n",
    "\n",
    "    # Define the numerical columns\n",
    "    numerical_cols = ['cc_num', 'amt', 'city_pop', 'unix_time']\n",
    "\n",
    "    # Define the column transformer for preprocessing\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', 'passthrough', numerical_cols),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=True), new_categorical_cols)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Apply the preprocessing to the training dataset\n",
    "    X_train_processed = preprocessor.fit_transform(new_df_Train[new_categorical_cols + numerical_cols])\n",
    "\n",
    "    # Apply the same preprocessing to the test dataset\n",
    "    X_test_processed = preprocessor.transform(new_df_Test[new_categorical_cols + numerical_cols])\n",
    "\n",
    "    # Convert to sparse DataFrames\n",
    "    encoded_feature_names = preprocessor.named_transformers_['cat'].get_feature_names_out(new_categorical_cols)\n",
    "    all_feature_names = numerical_cols + list(encoded_feature_names)\n",
    "    X_train_processed_df = pd.DataFrame.sparse.from_spmatrix(X_train_processed, columns=all_feature_names)\n",
    "    X_test_processed_df = pd.DataFrame.sparse.from_spmatrix(X_test_processed, columns=all_feature_names)\n",
    "\n",
    "\n",
    "    continuous_cols = ['cc_num', 'amt', 'city_pop', 'unix_time']\n",
    "    binary_cols = [col for col in X_train_processed_df.columns if col not in continuous_cols]\n",
    "\n",
    "    # Normalize continuous columns\n",
    "    scaler = StandardScaler()\n",
    "    X_train_processed_df[continuous_cols] = scaler.fit_transform(dfTrain[continuous_cols])\n",
    "\n",
    "    # The binary columns do not require normalization\n",
    "    # If needed, ensure binary columns are in correct format (0 or 1)\n",
    "    X_train_processed_df[binary_cols] = X_train_processed_df[binary_cols].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "    continuous_cols = ['cc_num', 'amt', 'city_pop', 'unix_time']\n",
    "    binary_cols = [col for col in X_test_processed_df.columns if col not in continuous_cols]\n",
    "\n",
    "    # Normalize continuous columns\n",
    "    scaler = StandardScaler()\n",
    "    X_test_processed_df[continuous_cols] = scaler.fit_transform(dfTest[continuous_cols])\n",
    "\n",
    "    # The binary columns do not require normalization\n",
    "    # If needed, ensure binary columns are in correct format (0 or 1)\n",
    "    X_test_processed_df[binary_cols] = X_test_processed_df[binary_cols].astype(int)\n",
    "    X_train = X_train_processed_df\n",
    "    X_test = X_test_processed_df\n",
    "    y_train = new_df_Train['is_fraud']\n",
    "    y_test = new_df_Test['is_fraud']\n",
    "    return X_train,X_test,y_train,y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2a2c01-c54d-4867-a22e-9b33d08f6387",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
